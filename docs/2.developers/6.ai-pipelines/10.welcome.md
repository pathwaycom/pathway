---
title: "Welcome"
description: "Welcome to Pathway AI Pipelines Documentation!"
navigation: true
heading: false
toc: false
---

# Welcome to Pathway AI Pipelines Documentation!

Pathway AI Pipelines are ready-to-run templates for RAG and LLMs pipelines, and enterprise search with live data.


::article-img
---
src: '/assets/content/documentation/Products-diag.svg'
alt: 'Pathway Product overview'
title: "Pathway Product overview: Pathway Core Framework and RAG app"
quality: '100'
class: 'mx-auto'
sizes: '100vw'
zoomable: true
---
::


If you are looking for the Pathway Live Data Framework, the Python data stream processing framework behind the AI Pipelines, you can find the associated docs [here](/developers/user-guide/introduction/welcome).

Pathway's AI Pipelines allow you to quickly put in production AI applications which offer high-accuracy RAG and AI enterprise search at scale using the most up-to-date knowledge available in your data sources. You can test them on your own machine and deploy on-cloud (GCP, AWS, Azure, Render, ...) or on-premises.

The apps connect and sync (all new data additions, deletions, updates) with data sources on your file system, Google Drive, Sharepoint, S3, Kafka, PostgreSQL, real-time data APIs. They come with no infrastructure dependencies that would need a separate setup. They include built-in data indexing enabling vector search, hybrid search, and full-text search - all done in-memory, with cache.

<!-- https://www.canva.com/design/DAGW6gYJ1VM/Nt_2VEzbAfW_OyJSuj_krQ/edit?utm_content=DAGW6gYJ1VM&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton -->
::article-img
---
src: '/assets/content/documentation/RAG-pipeline-overview.svg'
alt: 'AI Pipelines overview'
title: "Pathway Product overview: AI Pipelines overview"
quality: '100'
class: 'mx-auto'
sizes: '90vw'
---
::



::container{.flex .gap-8 .mt-4 .items-center .w-full .justify-center}
    ::pathway-button{icon="uil:github" type="secondary" href="/developers/ai-pipelines/quick-start"}
    Quick Start
    ::
::


#### Application Templates

The application templates provided in this repo scale up to millions of pages of documents. Some of them are optimized for simplicity, some are optimized for amazing accuracy. Pick the one that suits you best. You can use it out of the box, or change some steps of the pipeline - for example, if you would like to add a new data source, or change a Vector Index into a Hybrid Index, it's just a one-line change.

::card-grid{columns="2"}
#default
    ::landing-card
    ---
    icon: 'heroicons:bolt-solid'
    button:
        text: 'See the templates.'
        href: '/developers/templates#llm'
    ---
    #title
    Run a template

    #default
    Pathway AI Pipelines provide several ready-to-go templates for common use cases.
    Whether you need a real-time alerting system, document indexing, or context-based Q&A, you'll find templates for each.
    ::
    ::landing-card
    ---
    icon: 'heroicons:book-open-20-solid'
    button:
        text: 'Edit your YAML'
        href: '/developers/ai-pipelines/configure-yaml'
    ---
    #title
    Configure your app

    #default
    Customize your app to meet your needs without modifying Python code by using YAML configuration files.
    Learn more about the capabilities of Pathway's custom YAML parser, designed to simplify template configuration.
    ::
::
::card-grid{columns="2"}
#default
    ::landing-card
    ---
    icon: 'heroicons:bolt-solid'
    button:
        text: 'Build an LLM-app'
        href: '/developers/user-guide/llm-xpack/llm-app-pathway'
    ---
    #title
    Create your own app

    #default
    Not the template you were looking for?
    Create your own customized LLM app, and let us know what you are building, we are always adding new templates!
    ::
    ::landing-card
    ---
    icon: 'heroicons:book-open-20-solid'
    button:
        text: 'Learn more'
        href: '/developers/ai-pipelines/rest-api'
    ---
    #title
    REST API

    #default
    Our RAG templates rely on a REST API to communicate.
    ::
::



<!-- ::container{.flex .gap-8 .items-center .w-full .justify-center}
    ::pathway-button{icon="uil:github" type="secondary" href="/developers/templates#llm"}
    See the templates.
    ::
::

::container{.flex .gap-8 .items-center .w-full .justify-center}
    ::pathway-button{icon="uil:github" type="secondary" href="/developers/ai-pipelines/configure-yaml"}
    Configure an app
    ::
::

::container{.flex .gap-8 .items-center .w-full .justify-center}
    ::pathway-button{icon="uil:github" type="secondary" href="/developers/ai-pipelines/create-your-own"}
    Create your own
    ::
::

::container{.flex .gap-8 .items-center .w-full .justify-center}
    ::pathway-button{icon="uil:github" type="secondary" href="/developers/ai-pipelines/rest-api"}
    Rest API
    ::
:: -->

#### GitHub repository
Pathway AI Pipelines sources are available on GitHub.
Don't hesitate to clone the repo and contribute!

::container{.flex .gap-8 .items-center .w-full .justify-center}
    ::pathway-button{icon="uil:github" type="secondary" href="https://github.com/pathwaycom/llm-app"}
    See the sources
    ::
::

#### Based on Pathway Live Data Framework

The apps rely on the [Pathway framework](/developers/user-guide/introduction/welcome) for data source synchronization and for serving API requests (Pathway is a standalone Python library with a Rust engine built into it). They bring you a simple and unified application logic for back-end, embedding, retrieval, LLM tech stack. There is no need to integrate and maintain separate modules for your Gen AI app: Vector Database (e.g. Pinecone/Weaviate/Qdrant) + Cache (e.g. Redis) + API Framework (e.g. Fast API). Everything works out of the box.
